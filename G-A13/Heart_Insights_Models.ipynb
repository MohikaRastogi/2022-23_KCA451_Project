{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "In this code, various machine learning algorithms are applied to the \"heart.csv\" dataset. The dataset is split into features (X) and the target variable (y). Then, the data is split into training and testing sets. The features are standardized using the StandardScaler.\n",
        "\n",
        "A dictionary named models is created to store the different machine learning models to be evaluated. The code then trains and evaluates each model using the training and testing sets. The evaluation metrics used include accuracy, confusion matrix, and classification report.\n",
        "\n",
        "After evaluating the models, the code calculates and displays the feature importance ranking using the Random Forest classifier. This provides insights into which features are most influential in predicting the target variable.\n",
        "\n",
        "You can run this code in a Python environment to apply multiple machine learning algorithms and obtain insights from the \"heart.csv\" dataset. Feel free to modify the code to include additional models or tweak parameters based on your requirements."
      ],
      "metadata": {
        "id": "dTzJZAczHWzR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwM5ZgBoHFrg",
        "outputId": "0593ce2e-a0eb-460f-b1fd-4df1db407bfa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================ Logistic Regression ================\n",
            "Accuracy: 0.85\n",
            "Confusion Matrix:\n",
            "[[25  4]\n",
            " [ 5 27]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.86      0.85        29\n",
            "           1       0.87      0.84      0.86        32\n",
            "\n",
            "    accuracy                           0.85        61\n",
            "   macro avg       0.85      0.85      0.85        61\n",
            "weighted avg       0.85      0.85      0.85        61\n",
            "\n",
            "\n",
            "\n",
            "================ Decision Tree ================\n",
            "Accuracy: 0.80\n",
            "Confusion Matrix:\n",
            "[[27  2]\n",
            " [10 22]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.93      0.82        29\n",
            "           1       0.92      0.69      0.79        32\n",
            "\n",
            "    accuracy                           0.80        61\n",
            "   macro avg       0.82      0.81      0.80        61\n",
            "weighted avg       0.83      0.80      0.80        61\n",
            "\n",
            "\n",
            "\n",
            "================ Random Forest ================\n",
            "Accuracy: 0.84\n",
            "Confusion Matrix:\n",
            "[[24  5]\n",
            " [ 5 27]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.83      0.83        29\n",
            "           1       0.84      0.84      0.84        32\n",
            "\n",
            "    accuracy                           0.84        61\n",
            "   macro avg       0.84      0.84      0.84        61\n",
            "weighted avg       0.84      0.84      0.84        61\n",
            "\n",
            "\n",
            "\n",
            "================ Support Vector Machine ================\n",
            "Accuracy: 0.87\n",
            "Confusion Matrix:\n",
            "[[26  3]\n",
            " [ 5 27]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.90      0.87        29\n",
            "           1       0.90      0.84      0.87        32\n",
            "\n",
            "    accuracy                           0.87        61\n",
            "   macro avg       0.87      0.87      0.87        61\n",
            "weighted avg       0.87      0.87      0.87        61\n",
            "\n",
            "\n",
            "\n",
            "================ K-Nearest Neighbors ================\n",
            "Accuracy: 0.90\n",
            "Confusion Matrix:\n",
            "[[27  2]\n",
            " [ 4 28]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.93      0.90        29\n",
            "           1       0.93      0.88      0.90        32\n",
            "\n",
            "    accuracy                           0.90        61\n",
            "   macro avg       0.90      0.90      0.90        61\n",
            "weighted avg       0.90      0.90      0.90        61\n",
            "\n",
            "\n",
            "\n",
            "================ Naive Bayes ================\n",
            "Accuracy: 0.87\n",
            "Confusion Matrix:\n",
            "[[26  3]\n",
            " [ 5 27]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.90      0.87        29\n",
            "           1       0.90      0.84      0.87        32\n",
            "\n",
            "    accuracy                           0.87        61\n",
            "   macro avg       0.87      0.87      0.87        61\n",
            "weighted avg       0.87      0.87      0.87        61\n",
            "\n",
            "\n",
            "\n",
            "Feature Importance Ranking:\n",
            "1. ca: 0.1332\n",
            "2. cp: 0.1208\n",
            "3. oldpeak: 0.1184\n",
            "4. thalach: 0.1089\n",
            "5. thal: 0.0977\n",
            "6. age: 0.0887\n",
            "7. exang: 0.0776\n",
            "8. chol: 0.0774\n",
            "9. trestbps: 0.0685\n",
            "10. slope: 0.0416\n",
            "11. sex: 0.0353\n",
            "12. restecg: 0.0219\n",
            "13. fbs: 0.0100\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/heart.csv\")\n",
        "\n",
        "# Split the data into features (X) and target variable (y)\n",
        "X = data.drop('target', axis=1)\n",
        "y = data['target']\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Create a dictionary to store the models\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(),\n",
        "    \"Random Forest\": RandomForestClassifier(),\n",
        "    \"Support Vector Machine\": SVC(),\n",
        "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
        "    \"Naive Bayes\": GaussianNB()\n",
        "}\n",
        "\n",
        "# Train and evaluate each model\n",
        "for model_name, model in models.items():\n",
        "    print(f\"================ {model_name} ================\")\n",
        "    # Train the model\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "    # Evaluate the model\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(cm)\n",
        "\n",
        "    classification_rep = classification_report(y_test, y_pred)\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_rep)\n",
        "\n",
        "    print(\"\\n\")\n",
        "\n",
        "# Feature Importance (Random Forest)\n",
        "rf = RandomForestClassifier()\n",
        "rf.fit(X_train_scaled, y_train)\n",
        "importance = rf.feature_importances_\n",
        "feature_names = X.columns\n",
        "\n",
        "# Sort feature importances in descending order\n",
        "indices = np.argsort(importance)[::-1]\n",
        "\n",
        "# Print feature importance ranking\n",
        "print(\"Feature Importance Ranking:\")\n",
        "for i in range(len(importance)):\n",
        "    print(f\"{i+1}. {feature_names[indices[i]]}: {importance[indices[i]]:.4f}\")\n"
      ]
    }
  ]
}